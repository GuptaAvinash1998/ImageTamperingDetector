{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b105bd34-3048-49d3-be54-99b15cb0bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# PIL (Pillow) is a python image library that is used to handle operations on images\n",
    "# Image is an object representation of an Image for manipulation\n",
    "# ImageEnhance controls the brightness of the image\n",
    "# ImageChops (Chanel Operations) is a module that is used to apply arithmetic operations to images\n",
    "from PIL import Image, ImageEnhance, ImageChops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "import random\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5b4ae2-0b60-4fd7-ad02-3053b40915c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7d318f-9453-4002-9a57-500658e090c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the image data\n",
    "# the preprocessing step creates ELA images so that we filter out the unwanted file formats\n",
    "# ELA aka Error Level Analysis is a forensic technique that is used to analyze images by comparing\n",
    "# them through different levels of compression.\n",
    "def preProcessImages(imagesPath, file, resavePath):\n",
    "    \n",
    "    imagePath = os.path.join(imagesPath, file)\n",
    "        \n",
    "    #we accept 3 lossy file extensions: jpg, jpeg, and png. Process images in this formar only\n",
    "    if file.endswith('jpg') or file.endswith('jpeg') or file.endswith('png'):\n",
    "            \n",
    "        #open the image and convert it to RGB mode\n",
    "        image = Image.open(imagePath).convert('RGB')\n",
    "            \n",
    "        #resave the image with the new mode and as a jpg\n",
    "        # when we save an image with a quality of 90, that means we store the image\n",
    "        # with high quality but moderate compression\n",
    "        image.save('resavedImage.jpg', 'JPEG', quality=90)\n",
    "            \n",
    "        # reopen the resaved image\n",
    "        resavedImage = Image.open('resavedImage.jpg')\n",
    "            \n",
    "        # Calculate the ELA by taking the difference between the originial and the resaved image\n",
    "        elaImage = ImageChops.difference(image, resavedImage)\n",
    "            \n",
    "        # get the maximum pixel value\n",
    "        maxPixelValue = max([val[1] for val in elaImage.getextrema()])\n",
    "            \n",
    "        # if the max value is 0, set it to 1 so that we do not divide by 0\n",
    "        if(maxPixelValue <= 0):\n",
    "            maxPixelValue = 1\n",
    "                \n",
    "        # using the max value, scale the pixels to the range of [0,255]\n",
    "        scaleVal = 255.0/maxPixelValue\n",
    "            \n",
    "        #using the scaled value, enhance the image and save it\n",
    "        elaImage = ImageEnhance.Brightness(elaImage).enhance(scaleVal)\n",
    "            \n",
    "        #save the image in the reserved file path as a jpeg\n",
    "        elaImage.save(os.path.join(resavePath, os.path.basename(imagePath)), 'JPEG')\n",
    "        \n",
    "        # Resize the image to the input size expected by the model\n",
    "        elaImage = elaImage.resize((256, 256))  # Assuming InceptionV3 expects input size of 299x299\n",
    "\n",
    "        # Convert the image to a numpy array\n",
    "        imgArray = np.asarray(elaImage)\n",
    "\n",
    "        # Reshape the array to match the expected input shape of the model\n",
    "        #imgArray = np.expand_dims(img_array, axis=0)\n",
    "        imgArray = imgArray[np.newaxis, :]\n",
    "\n",
    "        return imgArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82775d7-a7ea-4654-9369-5b5545ad0fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " inception_v3 (Functional)   (None, 6, 6, 2048)           2180278   ['input_3[0][0]']             \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 2048)                 0         ['inception_v3[0][0]']        \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 2098176   ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (None, 1, 1024)              0         ['dense[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLamb  (None, 1, 1, 1024)           0         ['tf.expand_dims[0][0]']      \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 8, 8, 1024)           0         ['tf.expand_dims_1[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " vgg16 (Functional)          (None, 8, 8, 512)            1471468   ['input_3[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 8, 8, 1536)           0         ['up_sampling2d[0][0]',       \n",
      " )                                                                   'vgg16[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 1536)                 0         ['concatenate_2[0][0]']       \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1024)                 1573888   ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    1025      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40190561 (153.31 MB)\n",
      "Trainable params: 3673089 (14.01 MB)\n",
      "Non-trainable params: 36517472 (139.30 MB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = load_model('imageTemperingModel.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a47412a-7f1f-4885-b9e4-e9b3bab37d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleImagePath = '/Users/avinashgupta/Documents/Personal_Projects/MachineLearning-Projects/ImageTamperingDetection/data'\n",
    "sampleImage = 'yuleLog.jpg'\n",
    "resultPath = '/Users/avinashgupta/Documents/Personal_Projects/MachineLearning-Projects/ImageTamperingDetection/'\n",
    "\n",
    "resultImageArray = preProcessImages(sampleImagePath, sampleImage, resultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c0d95a-f2b0-4c86-9158-1a24c8b52afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(resultImageArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3050dd54-a2fd-4952-9d56-540e4bfef2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 587ms/step\n",
      "Image is authentic\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(resultImageArray)\n",
    "\n",
    "if predictions[0] < 0.5:\n",
    "    print(\"Image is authentic\")\n",
    "else:\n",
    "    print(\"Image is tempered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffe656-2dd2-48b7-bf14-b7ade8e7f76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
